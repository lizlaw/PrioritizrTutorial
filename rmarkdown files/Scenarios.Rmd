---
title: "Systematic Conservation Prioritization: Scenarios"
subtitle: Prioritizr demonstration - North Argentinian Dry Chaco example
author: Liz Law workingconservation@gmail.com
date: Humboldt Universit√§t - 2018
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Scenarios - descriptions and example code

Scenarios are one way to analyse the sensitivity of our results to different problem formulations, so we can get a better understanding of the system, our options, and what is driving the solutions.

For example, decision makers might want to ask us:  
- What happens if we change the targets?   
- What if we want to focus on different species groups?  How well do different groups proxy for others?
- What about different levels of connectivity?  
- What if we want different lock in - lock out scenarios?  
- What if we want a range of different solutions to discuss and explore?   

And what is the impact of these variations on the amount and type of areas selected, and the corresponding costs, etc.?

These can be developed with the scenarios below.

However, first we need to decide what we are comparing the scenario solutions against. 

### The reference point

This choice of 'reference point' is not trivial. It will frame our results, and color our opinion of what is good or bad. Here, we will set the 'reference point' as a reserve system that efficiently protects 17% of all the species (i.e. 17% of the maximum total value possible for each species), and locks in existing protected areas. 

*Why might we want this, rather than one without a lock in constraint?*
  
```{r, eval = FALSE, echo = TRUE}
# the reference point problem
p0 <- problem(soyprofit, stack(forestbirds, otherbirds, mammals)) %>%
  add_min_set_objective() %>%
  add_relative_targets(0.17) %>%
  add_locked_in_constraints(protectedareas>50) %>%
  add_binary_decisions() %>%
  add_lpsymphony_solver(gap=0.1) 

# and solution
s0 <- solve(p0)
```


## Scenarios
Now that we have our baseline, we can develop the different scenarios. We will do this in small groups, one for each scenario. Remember to allocate the problems and solutions to new objects, else they will write over previous problems/solutions.

We'd like you to prepare 5 slides on your scenario to present to the class in a 5 minute presentation. These 5 slides should show:  
- Introduction: what your scenario is, and why it is useful  
- Methods: how you implemented your analysis   
- Results: what these showed  
- Discussion: what this might mean for conservation planning in the region or more generally?  

Note 1: You will need to write your own code for these scenarios. We should be able to do this now, by modifying the code from the examples, and using the hints from below. But if you have questions, please ask! We want this exercise to be about conservation prioritization, and not learning how to use R. 

Note 2: We won't expect your maps to be fancy, but we would like them to show what you need to show. Most of the code you need to do these analyses can be derived from the examples in Exercise_2.html, or is given in the tips below. Feel free to develop any graphs here in R, or by copying the results over to Excel. 

Note 3: You might want to learn a little more about the functions available in Prioritizr. The full documentation is available in the [reference](https://prioritizr.net/reference/index.html). Or, remember you can always access the help file for a function by typing in the console a ? or ?? before the function, such as `?problem`. 

## Scenario 1: Target vs cost

We've been using a relative target of 17% to (roughly) align with global conservation targets (specifically, the [CBD Aichi Targets](https://www.cbd.int/sp/targets/), and more specifically, an interpretation of Target 11). But how do costs change with different choices for this relative target? If we can get a much larger target, for just a little bit more cost, this could be worth it. Or if we can get a more realistic cost, for just a little bit less target, perhaps this might be more socially or politically feasible. 

To examine this, we would like to make a graph that shows different values of relative target on the X axis, and different costs of the resulting solutions on the Y axis. 

We might also like to overlay the solutions to get a 'selection frequency' layer, which is a super simple way to start to understand where the really important areas are (provided the solutions are largely 'nested'). 

We can change the relative target by changing the number in the call, and this will update this specification in the problem. For example, we might create 'p10' which would achieve 10% of each feature species.  The following code will 'update' the relative target for our base problem, p0.

```{r, eval = FALSE, echo = TRUE}
# updating the relative targets
p10 <- p0 %>% 
  add_relative_targets(0.10) 

s10 <- solve(p10)
```  

Some discussion points:
  
  - *How does area selected scale with targets?*
  - *How does cost scale with targets?*
  - *What might be the ecological or political justification for different targets?*
  - *What might be the ecological or political consequences of different targets?*
  - *What might be better targets to apply?* 
  
## Scenario 2: Focus on different species groups
  
So far, we have included all the species we had data for, including forest birds, other birds, and mammals. But what if we are only interested in mammals? How well might a solution based only on mammals protect birds as well? Or vice versa? 

To test this, we might develop solutions for scenarios that only target certain species, or certain species groups, and then examine how well these would represent the other species. We might like to overlay the solutions to see areas of commonality, and areas of difference. 

To do this, we need to respecify the problem, only includeing mammals in the features:
```{r, eval = FALSE, echo = TRUE}
# changing the features to mammals only
p_mammalsonly <- problem(soyprofit, stack(forestbirds, otherbirds, mammals)) %>%
  add_min_set_objective() %>%
  add_relative_targets(0.17) %>%
  add_locked_in_constraints(protectedareas>50) %>%
  add_binary_decisions() %>%
  add_lpsymphony_solver(gap=0.1) 

s_mammalsonly <- solve(p_mammalsonly)
```  
Note, we could also can enter a vector of numbers into the relative targets, rather than just a single number, and thus change our focus this way. For example, if we only want to include mammals, we might enter a target of 0 for all the bird species, as in the code below. Remember we have 5 forest birds, 5 other birds, and 5 mammals, in order. The following code will 'update' the relative target for our base problem, p0.

Note, these targets are specified as threshold targets, i.e. the problem will try and achieve >= the target. So the example below is trying to get at least 0 for the birds, and at least 17% for the mammals. 

```{r, eval = FALSE, echo = TRUE}
# alternative formaulation: changing the targets to target mammals only
p_mammalsonly <- p0 %>% 
  add_relative_targets(c(0,0,0,0,0,
                         0,0,0,0,0,
                         0.17,0.17,0.17,0.17,0.17)) 

s_mammalsonly <- solve(p_mammalsonly)
```  
Which method is better? It depends on what other scenarios you are doing, and how many species you have. The second method saves you from having to respecify the whole problem each time, but the first is more data efficient. 

Some discussion points:
  
  - *How well do birds represent mammals, or mammals represent birds?*
  - *What does this mean for conservation planning in data poor regions? What species are commonly data rich/poor?*
  - *How well might conservation plans designed only for threatened species represent other types of species? Hint: what usually defines a 'threatened' species?*
  - *Can species only survive in protected areas? Why should we only consider the contribution of protected areas in our problem? Why might this be misleading?*
  
## Scenario 3: Connectivity vs cost
  
Connectivity might be ecologically good, but it can also cost more as the cells selected become 'sub-optimal' with respect to the basic problem (requiring more cells to achieve targets, or being more costly).

Therefore we might like to compare the cost of solutions with differing levels of connectivity. 

We might like to explore a range of blm penalties. Below we implement a penalty of 0.05. We might want to explore options of blm penalties in c(0.001, 0.005, 0.01, 0.05, 0.1, 0.5). What do these different solutions look like? What is the trade-off between the blm penalty and cost?

Note: a reasonable blm penalty depends on your data, including the magnitude and units of the cost and boundary data, and how these and the benefits are distributed. But a useful rule of thumb to start is to find the point where the average cell cost is equal to the sum of the cell's boundary penalty. If the penalty is set too low, it will not have the magnitude to influence the decision enough to develop the desired level of clumping. If set too high, the solution will be driven more by the configuration rather than the species distributions. This in itself may be ok (the solution will still 'represent' all the species), but we may need to be wary if there are cells that are locked in - these will 'seed' solutions around themselves. Again, not necessarily a bad thing in some contexts, but not so desirable in others. It will also probably take a lot longer to solve.

Note: the 'edge_factor' modifies the penalty given to the boundary on the edge of the study region. If we want to keep solutions from the edge we might increase this factor. If we want to cluster solutions against the edges we might decrease this number. For now, to keep things simple, keep this factor at 0.5, and use the same blm data that we derived above.

```{r, eval = FALSE, echo = TRUE}
# adding a boundary penalty
p_blm1 <- p0 %>% 
  add_boundary_penalties(penalty = 0.05, edge_factor = 0.5, boundary_data = blm)

s_blm1 <- solve(p_blm1)
``` 

Note: because this method adds the boundary penalty to the cost, it changes the meaning of the objective function, and the objective value is no longer equal to just the cost itself. This means we need to calculate the cost using the `cellStats(s_blm1*soyprofit, sum)` command, rather than just looking at the objective attribute via `s_blm1@objective` 

Note: when adding connectivity to an existing problem, be sure there is not already a connectivity penalty existing in the problem - otherwise prioritizr will just add the new connectivity penalty, as well as keeping the old one. 

Some discussion points:  
  - *Why is connectivity useful, and how does the boundary penalties function implement this?* 
  - *How many more cells are selected, and at what extra cost, for the different levels of connectivity?*  
  - *Can you see the impact of locking in protected areas on connectivity? Might it influence which cells are selected? How might we go about changing this?*  
  - *How might this simple method of clustering cells not really be what we want, in ecological terms? What are the other options in Prioritizr that could be better?*  
  
## Scenario 4: Lock in - Lock out options
  
There are certain areas that really should be part of the solutions, such as existing protected areas. These are areas that might be protected for different reasons (e.g. cultural significance).  They might also not 'cost' anything, because they are already protected, and not available for other uses. 

However, remember the 'high and far bias'? So these existing protected areas may be really inefficient, and we could get a more efficient reserve system by completely re-thinking things. 

Similarly, there are reasons why some areas should really not be included in the reserve system. For example, if they are not politically feasible to protect - such as areas that are already in private land and with considerable private investment (e.g. urban or intensive agriculture), then it might be better to consider alternative conservation actions, and not allocate these to protected areas. Alternatively, spillovers such as invasive species, chemical run-off or drift from intensive agricultural areas may pose a risk to conservation assets, so we may want to avoid these areas for ecological reasons as well. 

Sometimes the 'cost' data is enough to push solutions away from these areas (or the feature benefit data towards them), but usually it is best to specify this directly into the problem.

We learnt how to lock in and lock out areas in the example above, using the constraints:
  
```{r, eval = FALSE, echo = TRUE}
# locking in protected areas
p_lin <- p0 %>% 
  add_locked_in_constraints(protectedareas>50) 

s_lin <- solve(p_lin)

# locking out intensive areas
p_lout <- p0 %>% 
  add_locked_out_constraints(intensiveareas>50) 

s_lout <- solve(p_lout)
``` 

We can compare these to a version of the problem that doesn't have the lock in/out constraints. Hint: while you can pipe new specifications onto existing problems, you may need to re-construct a problem to remove them. My recommendation is: if in doubt, re-specify the problem from scratch. 

We also might like to consider other options here, for example avoiding the areas with a forest smallholder density greater than a certain number.

Then, we can compare the cost and patterns of the solutions. 

A more advanced method of looking at the contribution of the existing protected areas to an optimized solution that locks them in, is to restrict (i.e. lockout) the problem to the area of the solution where they are locked in, but do not lock them in, and then see if they are still in the new solution. For example:

```{r, eval = FALSE, echo = TRUE}
# we have our lockin solution from above
s_lin

# we can create a lockout from the inverse of this
newlockout <- s_lin - 1
newlockout[newlockout==-1] <- 1

# then use this in the new problem specification, without pa locked in
# remember, to remove a lock-in, we need to respecify the problem from scratch!

p_newlout <- problem(soyprofit, stack(forestbirds, otherbirds, mammals)) %>%
  add_min_set_objective() %>%
  add_relative_targets(0.17) %>%
  add_binary_decisions() %>%
  add_lpsymphony_solver(gap=0.1) %>% 
  add_locked_out_constraints(newlockout)

# then we can compare the solutions, adding and plotting, etc.
``` 


Some discussion points:

- *Why might we lock in or lock out certain areas?*
- *How is locking in/out different from specifying this through the cost layer?*
- *What is the 'cost' of locking in/out certain areas in terms of lost opportunity to agriculture or area?*
- *What are the cells that are selected differently?*
- *What does the 'cost' we are using represent, and what are its benefits, and shortcomings?*
- *What other data might be useful here? Where or how might we get these data?*

## Scenario 5: A portfolio of solutions

The 'optimal' solution found by Prioritizr is usually an optimal option, as defined by the problem entered... but what if multiple options are all pretty good? What if we want to consider this range of options? 

Prioritizr offers a couple of ways to explore these, in [portfolios](https://prioritizr.net/reference/index.html#section-portfolios)

Note, when generating these solutions it is often good to reduce the optimality criterion (via increasing the `gap` parameter). This results in any one solution perhaps not being as optimal as previously, but results in a greater range of scenarios that are at least as good as the gap you specify. 

We will use the `add_shuffle_portfolio` option, which reshuffles the input data randomly. This is the quickest option. Because the solver returns the first best solution in the list of best solutions that satisfy the optimality gap criterion, the order of data input is often important. For example, the following code will attempt 10 different re-shuffles of the data, but only return the solutions that do not duplicate others.

Note, because this procedure involves a randomization procedure, if we want to replicate it exactly later, we need to `set.seed()` to a certain number. 

```{r, eval = FALSE, echo = TRUE}
# set the random number seed
set.seed(123)

# add a shuffle portfolio
p_shuf10 <- p0 %>% 
  add_shuffle_portfolio(number_solutions = 10, remove_duplicates = TRUE) %>%
  add_default_solver(gap = 0.2, verbose = FALSE)

s_shuf10 <- solve(p_shuf10)
``` 

This then returns not just a single raster layer with the solution, and associated attributes, but rather a stack of raster layers, and associated attributes. In other words, while we `plot(s0)` for the basic solution, we might `plot(stack(s_shuf10))` to see all the different solutions.

For each of these portfolios, we might also want to create a layer with the 'selection frequency', or how many times each cell was selected. For this we would sum the layers in the stack of solutions, to give one layer for each portfolio. 

```{r, eval = FALSE, echo = TRUE}
# calculate the selection frequencies
s_shuf10_freq <- sum(stack(s_shuf10))

# then plot this layer
plot(s_shuf10_freq)
```
Important note: We have to be careful when interpreting these selection frequency figures. High frequencies do mean that those cells were selected in multiple solutions. But even the cells that are low frequency were important in their respective solutions. 

Note: A more precise way of estimating replacability is by first identifying different clumps (e.g. by using the `raster::clump()` function), and then iteratively adding a lockout that includes each clump in turn. 

Some discussion points:
  
  - *Where are the areas that seem easily replacable, and where are the areas that are more irreplacable?*
  - *How might we recommend this information be used in a conservation planning process?*
  - *Suppose we identify a group of cells as 'important', but this area turns out to have an invasive species in it that requires an extra cost. How could we work out if it is worthwhile to include these cells, and pay to manage the invasive species, or to avoid these cells and select others? What might be the implication of these two strategies for conservation more generally?* 
  
